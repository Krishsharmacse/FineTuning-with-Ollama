# Fine-Tuning with Ollama (GGUF-safe Repository)

This repository demonstrates **fine-tuning a lightweight LLM and running it with Ollama**, while following best practices for GitHub (âš ï¸ **no large model files committed**).

The goal of this project is to:

* Fine-tune an LLM locally (CPU-friendly workflow)
* Convert the fine-tuned model to **GGUF** format
* Run and test the model using **Ollama**
* Keep the GitHub repo clean (code-only, no heavy artifacts)

---

## ğŸš€ Features

* Local fine-tuning workflow (no mandatory GPU)
* GGUF model support for Ollama
* Clean Git history (models excluded)
* Beginner-friendly and reproducible

---

## ğŸ“‚ Project Structure

```
FineTuning-with-Ollama/
â”‚
â”œâ”€â”€ endtoend_finetunning.ipynb   # Complete fine-tuning pipeline
â”œâ”€â”€ ollama-test/                # Ollama-related configs (no models)
â”œâ”€â”€ .gitignore                  # Ignores GGUF & large model files
â”œâ”€â”€ README.md                   # Project documentation
â””â”€â”€ requirements.txt            # Python dependencies (optional)
```

> âš ï¸ **Important:** `.gguf`, `.bin`, and `.safetensors` files are intentionally ignored and must NOT be committed.

---

## ğŸ§  Workflow Overview

1. **Prepare Dataset**

   * Load and preprocess training data

2. **Fine-tune Base Model**

   * Uses lightweight LLM (e.g., TinyLLaMA)
   * CPU-compatible (slow but works)

3. **Export to GGUF**

   * Convert HuggingFace model â†’ GGUF

4. **Run with Ollama**

   * Create Modelfile
   * Run locally using `ollama run`

---

## ğŸ§ª Fine-Tuning Notebook

The full pipeline is implemented in:

```
endtoend_finetunning.ipynb
```

This notebook includes:

* Environment setup
* Model loading
* Training loop
* GGUF conversion
* Ollama testing

---

## ğŸ¦™ Running with Ollama

Example Modelfile:

```text
FROM ./model.gguf

PARAMETER temperature 0.7
PARAMETER top_p 0.9
```

Build and run:

```bash
ollama create my-model -f Modelfile
ollama run my-model
```

---

## ğŸ§¾ GitHub Safety Rules

This repo follows **strict GitHub-safe rules**:

```gitignore
*.gguf
*.bin
*.safetensors
__pycache__/
venv/
.env
```

Large models should be stored **locally or externally**, not in Git.

---

## ğŸ“¦ Model Storage (Recommended)

Store trained models using:

* Local disk
* External drive
* Hugging Face Hub (private/public)

GitHub = **code only** âœ…

---

## ğŸ›  Requirements

* Python 3.9+
* Ollama
* llama.cpp
* PyTorch
* transformers

Install Ollama:
ğŸ‘‰ [https://ollama.com](https://ollama.com)

---

## ğŸ‘¨â€ğŸ’» Author

**Krish Sharma**
AI / ML Engineer

---

## ğŸ“œ License

This project is for educational and research purposes.

---

â­ If this repo helped you, consider giving it a star!
