{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "457deef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =========================\n",
    "# Config\n",
    "# =========================\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Without seed → every shuffle is different\n",
    "# With seed = 3407 → the shuffle order is always the same\n",
    "# Dataset shuffling\n",
    "# NumPy-based preprocessing\n",
    "# Augmentations\n",
    "\n",
    "# Weight initialization on CPU\n",
    "# CPU tensor randomness\n",
    "\n",
    "# GPU randomness\n",
    "# Dropout\n",
    "# Attention kernels\n",
    "# CUDA operations\n",
    "\n",
    "SEED = 3407\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "\n",
    "#Do matrix multiplications faster, without breaking training quality.\n",
    "# This controls how aggressive PyTorch is when using fast math.\n",
    "# Faster & stable matmul on NVIDIA GPUs\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "max_seq_length = 4096        # Demonstrates long-context + RoPE scaling\n",
    "dtype = None                # Auto-detect (FP16 on T4, BF16 on A100/L4)\n",
    "load_in_4bit = True         # Memory-efficient QLoRA-style loading\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0e8cad6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# GPU sanity check\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available()\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# GPU sanity check\n",
    "assert torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8c149b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Unsloth cannot find any torch accelerator? You need a GPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# =========================\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Imports\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# =========================\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01munsloth\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FastLanguageModel\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtrl\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SFTTrainer, SFTConfig\n",
      "File \u001b[1;32md:\\ollama finetune\\venv\\lib\\site-packages\\unsloth\\__init__.py:95\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m     84\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsloth: Please update Unsloth and Unsloth-Zoo to the latest version!\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     85\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDo this via `pip install --upgrade --force-reinstall --no-cache-dir --no-deps unsloth unsloth_zoo`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     86\u001b[0m         )\n\u001b[0;32m     87\u001b[0m         \u001b[38;5;66;03m# if os.environ.get(\"UNSLOTH_DISABLE_AUTO_UPDATES\", \"0\") == \"0\":\u001b[39;00m\n\u001b[0;32m     88\u001b[0m         \u001b[38;5;66;03m#     try:\u001b[39;00m\n\u001b[0;32m     89\u001b[0m         \u001b[38;5;66;03m#         os.system(\"pip install --upgrade --no-cache-dir --no-deps unsloth_zoo\")\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[38;5;66;03m#         except:\u001b[39;00m\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;66;03m#             raise ImportError(\"Unsloth: Please update unsloth_zoo via `pip install --upgrade --no-cache-dir --no-deps unsloth_zoo`\")\u001b[39;00m\n\u001b[1;32m---> 95\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01munsloth_zoo\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m PackageNotFoundError:\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m     98\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsloth: Please install unsloth_zoo via `pip install unsloth_zoo` then retry!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     99\u001b[0m     )\n",
      "File \u001b[1;32md:\\ollama finetune\\venv\\lib\\site-packages\\unsloth_zoo\\__init__.py:146\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m logging, torchao_logger, HideLoggingMessage\n\u001b[0;32m    145\u001b[0m \u001b[38;5;66;03m# Get device types and other variables\u001b[39;00m\n\u001b[1;32m--> 146\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdevice_type\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m    147\u001b[0m     is_hip,\n\u001b[0;32m    148\u001b[0m     get_device_type,\n\u001b[0;32m    149\u001b[0m     DEVICE_TYPE,\n\u001b[0;32m    150\u001b[0m     DEVICE_TYPE_TORCH,\n\u001b[0;32m    151\u001b[0m     DEVICE_COUNT,\n\u001b[0;32m    152\u001b[0m     ALLOW_PREQUANTIZED_MODELS,\n\u001b[0;32m    153\u001b[0m )\n\u001b[0;32m    155\u001b[0m \u001b[38;5;66;03m# Torch 2.9 removed PYTORCH_HIP_ALLOC_CONF and PYTORCH_CUDA_ALLOC_CONF\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m major_torch \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m minor_torch \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m9\u001b[39m:\n",
      "File \u001b[1;32md:\\ollama finetune\\venv\\lib\\site-packages\\unsloth_zoo\\device_type.py:56\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsloth currently only works on NVIDIA, AMD and Intel GPUs.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m DEVICE_TYPE : \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mget_device_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# HIP fails for autocast and other torch functions. Use CUDA instead\u001b[39;00m\n\u001b[0;32m     58\u001b[0m DEVICE_TYPE_TORCH \u001b[38;5;241m=\u001b[39m DEVICE_TYPE\n",
      "File \u001b[1;32md:\\ollama finetune\\venv\\lib\\site-packages\\unsloth_zoo\\device_type.py:46\u001b[0m, in \u001b[0;36mget_device_type\u001b[1;34m()\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccelerator\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[1;32m---> 46\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsloth cannot find any torch accelerator? You need a GPU.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     47\u001b[0m     accelerator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(torch\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mcurrent_accelerator())\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m accelerator \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxpu\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhip\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: Unsloth cannot find any torch accelerator? You need a GPU."
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Imports\n",
    "# =========================\n",
    "from unsloth import FastLanguageModel\n",
    "from datasets import load_dataset\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7e1dbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
